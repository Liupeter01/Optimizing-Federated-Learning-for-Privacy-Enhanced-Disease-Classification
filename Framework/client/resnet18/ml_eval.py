# âœ… 8ï¸âƒ£ ä½¿ç”¨éªŒè¯é›†è¯„ä¼°æœ€ç»ˆæ¨¡å‹ï¼ˆä¿æŒç»“æ„ä¸€è‡´ + æ‰‹åŠ¨ä¼ å…¥æœ€ä½³å‚æ•°ï¼‰
def evaluate_on_val():
    # device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    device = torch.device("mps" if torch.cuda.is_available() else "cpu")

    # âœ… æ‰‹åŠ¨è¾“å…¥æœ€ä½³å‚æ•°ï¼ˆè¯·æ›¿æ¢ä¸ºä½ æœ€ç»ˆé€‰å‡ºçš„æœ€ä½³ç»„åˆï¼‰
    best_config = {
        'dropout': 0.4,
        'lr': 0.00015,
        'batch_size': 100,
        'optimizer': 'adam',
        'kernel_size': 4,
        'num_blocks': 2,
        'fc_hidden_size': 515,
        'weight_decay': 0.0008,
        'augmentation': 'none',  # ğŸ”¹ éªŒè¯é›†ä¸å¢å¼º
        'loss_type': 'focal',
        'gamma': 2.0
    }

    # âœ… è½½å…¥éªŒè¯é›†
    val_df = pd.read_csv("val_group1_smart.csv")
    class_list = sorted(set('|'.join(val_df['Finding Labels']).split('|')))

    val_dataset = ChestXrayDataset(
        val_df, "Preprocessed_Images/Group2", class_list, augmentation='none')
    val_loader = DataLoader(val_dataset, batch_size=best_config['batch_size'])

    # âœ… æ„å»ºæ¨¡å‹ç»“æ„å¹¶åŠ è½½æƒé‡
    model = create_model(len(class_list), best_config['dropout'], best_config['fc_hidden_size'],
                         best_config['kernel_size'], best_config['num_blocks']).to(device)
    model.load_state_dict(torch.load(
        "best_resnet18_custom.pth", map_location=device))
    model.eval()

    # âœ… è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    all_preds, all_labels = [], []
    criterion = nn.BCEWithLogitsLoss()
    val_loss = 0

    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            val_loss += criterion(outputs, labels).item()
            probs = torch.sigmoid(outputs)
            preds = (probs > 0.5).float().cpu()
            all_preds.append(preds)
            all_labels.append(labels.cpu())

    y_true = torch.cat(all_labels, dim=0).numpy()
    y_pred = torch.cat(all_preds, dim=0).numpy()

    f1 = f1_score(y_true, y_pred, average='micro')
    precision = precision_score(
        y_true, y_pred, average='micro', zero_division=0)
    recall = recall_score(y_true, y_pred, average='micro', zero_division=0)

    print("\nğŸ§ª éªŒè¯é›†è¯„ä¼°ç»“æœï¼š")
    print(f"F1: {f1:.4f} | Precision: {precision:.4f} | Recall: {
          recall:.4f} | Loss: {val_loss / len(val_loader):.4f}")


# âœ… è¿è¡ŒéªŒè¯è¯„ä¼°ï¼ˆè¯·æ‰‹åŠ¨è¿è¡Œï¼‰
evaluate_on_val()
